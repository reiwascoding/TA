{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import argparse\n",
    "import monai\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "from torchmetrics.functional import iou, dice_score\n",
    "from torch import nn\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import datetime\n",
    "import monai.transforms as mt\n",
    "from torchmetrics import IoU, F1\n",
    "from unet import Unet_2d\n",
    "from dataload import train_loader_ACDC, val_loader_ACDC\n",
    "from monai.losses.dice import DiceLoss, DiceCELoss\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator as ea\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_choice = \"UNet2D\"\n",
    "k_folds = 2\n",
    "loss_choice = \"dice\"\n",
    "batch_size_train = 5\n",
    "batch_size_val = 1\n",
    "learning_rate = np.float32(0.0005)\n",
    "LR_decay_rate = np.float32(0.985)\n",
    "gpus = 1\n",
    "max_epochs = 30\n",
    "patience = 30\n",
    "optim_choice = 'adam'\n",
    "scheduler_choice = 'plateau'\n",
    "drop_rate = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Choice: UNet2D Dropout Rate 0.3 K Folds: 2 Loss Choice: dice LR Decay Rate: 0.985 Device: 1 Patience Early Stopping: 30 Optimizer: adam Scheduler: plateau\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Choice:\", model_choice,\n",
    "      \"Dropout Rate\", drop_rate,\n",
    "      \"K Folds:\", k_folds,\n",
    "      \"Loss Choice:\", loss_choice,\n",
    "      \"LR Decay Rate:\", LR_decay_rate,\n",
    "      \"Device:\", gpus,\n",
    "      \"Patience Early Stopping:\", patience,\n",
    "      \"Optimizer:\", optim_choice,\n",
    "      \"Scheduler:\", scheduler_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_choice == \"UNet2D\":\n",
    "    my_model = Unet_2d(drop=drop_rate).cuda()  # with upsample --> Has more parameters\n",
    "else:\n",
    "    raise ValueError(\"Wrong model choice!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_choice == \"dice_ce\":\n",
    "    loss_func = DiceCELoss(include_background=True,\n",
    "                           to_onehot_y=True,\n",
    "                           sigmoid=False,\n",
    "                           softmax=True,\n",
    "                           jaccard=False,\n",
    "                           reduction=\"mean\",\n",
    "                           smooth_nr=1e-05,\n",
    "                           smooth_dr=1e-05,\n",
    "                           # ce_weight=class_weights,\n",
    "                           batch=False).cuda()\n",
    "elif loss_choice == \"dice\":\n",
    "    loss_func = DiceLoss(include_background=True,\n",
    "                         to_onehot_y=True,\n",
    "                         sigmoid=False,\n",
    "                         softmax=True,\n",
    "                         jaccard=False,\n",
    "                         reduction=\"mean\",\n",
    "                         smooth_nr=1e-05,\n",
    "                         smooth_dr=1e-05,\n",
    "                         batch=False).cuda()\n",
    "else:\n",
    "    raise ValueError(\"Wrong loss choice!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU\n",
    "IOU_metric = IoU(num_classes=4, absent_score=-1., reduction=\"none\").cuda()\n",
    "# F1 score\n",
    "f1_metric = F1(num_classes=4, mdmc_average=\"samplewise\", average='none').cuda()\n",
    "# Softmax\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "# Required dimensions\n",
    "tar_shape = [300, 300]\n",
    "crop_shape = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_largest = monai.transforms.KeepLargestConnectedComponent(applied_labels=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = mt.Compose(\n",
    "    [mt.ResizeWithPadOrCropD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"constant\"),\n",
    "     mt.RandSpatialCropD(keys=[\"image\", \"mask\"], roi_size=crop_shape, random_center=True, random_size=False),\n",
    "     mt.Rand2DElasticD(\n",
    "         keys=[\"image\", \"mask\"],\n",
    "         prob=0.25,\n",
    "         spacing=(50, 50),\n",
    "         magnitude_range=(1, 3),\n",
    "         rotate_range=(np.pi / 4,),\n",
    "         scale_range=(0.1, 0.1),\n",
    "         translate_range=(10, 10),\n",
    "         padding_mode=\"border\",\n",
    "     ),\n",
    "     # mt.RandScaleIntensityd(keys=[\"image\"], factors=0.3, prob=0.15),\n",
    "     mt.RandFlipd([\"image\", \"mask\"], spatial_axis=[0], prob=0.5),\n",
    "     mt.RandFlipd([\"image\", \"mask\"], spatial_axis=[1], prob=0.5),\n",
    "     mt.RandRotateD(keys=[\"image\", \"mask\"], range_x=np.pi / 4, range_y=np.pi / 4, range_z=0.0, prob=0.50,\n",
    "                    keep_size=True, mode=(\"nearest\", \"nearest\"), align_corners=False),\n",
    "     mt.RandRotate90D(keys=[\"image\", \"mask\"], prob=0.25, spatial_axes=(0, 1)),\n",
    "     mt.RandGaussianNoiseD(keys=[\"image\"], prob=0.15, std=0.01),\n",
    "     mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "     mt.RandZoomd(\n",
    "         keys=[\"image\", \"mask\"],\n",
    "         min_zoom=0.9,\n",
    "         max_zoom=1.2,\n",
    "         mode=\"nearest\",\n",
    "         align_corners=None,\n",
    "         prob=0.25,\n",
    "     ),\n",
    "     mt.RandKSpaceSpikeNoiseD(keys=[\"image\"], prob=0.15, intensity_range=(5.0, 7.5)),\n",
    "     ]\n",
    ")\n",
    "val_transform = mt.Compose([\n",
    "    mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "splits = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "# train + val dataset for 5 fold cross validation training\n",
    "concatenated_dataset = train_loader_ACDC(transform=None, train_index=None)\n",
    "\n",
    "#  paths to store the checkpoints\n",
    "if not os.path.exists(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/checkpoints\"):\n",
    "    os.makedirs(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/checkpoints\")\n",
    "checkpoint_path = \"D:\\Kodingan\\Kodingan TA\\\\TA/unet/checkpoints\"\n",
    "\n",
    "if not os.path.exists(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/tb_logs\"):\n",
    "    os.makedirs(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/tb_logs\")\n",
    "tb_path = \"D:\\Kodingan\\Kodingan TA\\Arkanandi/unet/tb_logs\"\n",
    "\n",
    "if not os.path.exists(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/csv_logs\"):\n",
    "    os.makedirs(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/csv_logs\")\n",
    "csv_path = \"D:\\Kodingan\\Kodingan TA\\\\TA/unet/csv_logs\"\n",
    "\n",
    "#  Temporarily store the validated image and ground truth plots --> to be moved to the respective folders\n",
    "if not os.path.exists(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/val_images_temp_2d/'):\n",
    "    os.makedirs(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/val_images_temp_2d/')\n",
    "val_path = r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/val_images_temp_2d/'\n",
    "\n",
    "# Save the validation images and ground truths\n",
    "if not os.path.exists(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/val_images_save_2d/'):\n",
    "    os.makedirs(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/val_images_save_2d/')\n",
    "image_path = r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/val_images_save_2d/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pad_images(image):\n",
    "    orig_shape = list(image.size())\n",
    "    original_x = orig_shape[2]\n",
    "    original_y = orig_shape[3]\n",
    "    new_x = (16 - (original_x % 16)) + original_x\n",
    "    new_y = (16 - (original_y % 16)) + original_y\n",
    "    new_shape = [new_x, new_y]\n",
    "    b, c, h, w = image.shape\n",
    "    m = image.min()\n",
    "    x_max = new_shape[0]\n",
    "    y_max = new_shape[1]\n",
    "    result = torch.Tensor(b, c, x_max, y_max).fill_(m)\n",
    "    xx = (x_max - h) // 2\n",
    "    yy = (y_max - w) // 2\n",
    "    result[:, :, xx:xx + h, yy:yy + w] = image\n",
    "    return result, tuple([xx, yy])  # result is a torch tensor in CPU --> have to move to GPU\n",
    "\n",
    "\n",
    "# pass the padded image, the indices and the original shape\n",
    "def UnPad_imges(image, indices, org_shape):\n",
    "    b, c, h, w = org_shape\n",
    "    xx = indices[0]\n",
    "    yy = indices[1]\n",
    "    return image[:, :, xx:xx + h, yy:yy + w]  # image is a torch tensor --> have to move to GPU\n",
    "\n",
    "\n",
    "# reset the parameters of the model\n",
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.Conv2d) or \\\n",
    "            isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.ConvTranspose3d):\n",
    "        m.reset_parameters()\n",
    "\n",
    "\n",
    "# save the masks\n",
    "def save_plots_mask(target, idx):\n",
    "    out_path = os.path.join(val_path, f\"{idx}_gt\" + \".\" + 'png')\n",
    "    out_save_path = os.path.join(image_path, f\"{idx}_gt\" + \".\" + 'png')\n",
    "    target = target.squeeze()\n",
    "    target = np.array(target.cpu())\n",
    "    plt.imsave(out_save_path, target)\n",
    "    image_file_name = str(idx) + \"_gt\"\n",
    "    plt.title = image_file_name\n",
    "    plt.imsave(out_path, target, format='png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# save the predictions\n",
    "def save_plots_pred(pred, idx):\n",
    "    out_path = os.path.join(val_path, f\"{idx}_pred\" + \".\" + 'png')\n",
    "    out_save_path = os.path.join(image_path, f\"{idx}_pred\" + \".\" + 'png')\n",
    "    soft_pred_log = soft(pred)\n",
    "    final_pred_log = torch.argmax(soft_pred_log, dim=1)\n",
    "    #  Post Processing after softmax and argmax\n",
    "    final_pred_log = keep_largest(final_pred_log)\n",
    "    final_pred_log = np.array(final_pred_log.cpu().squeeze())\n",
    "    plt.imsave(out_save_path, final_pred_log)\n",
    "    image_file_name = str(idx) + \"_pred\"\n",
    "    plt.title = image_file_name\n",
    "    plt.imsave(out_path, final_pred_log, format='png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# save the images\n",
    "def save_plots_image(img, idx):\n",
    "    out_path = os.path.join(val_path, f\"{idx}_image\" + \".\" + 'png')\n",
    "    out_save_path = os.path.join(image_path, f\"{idx}_image\" + \".\" + 'png')\n",
    "    final_image = np.array(img.cpu().squeeze())\n",
    "    plt.imsave(out_save_path, final_image)\n",
    "    image_file_name = str(idx) + \"_image\"\n",
    "    plt.title = image_file_name\n",
    "    plt.imsave(out_path, final_image, format='png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train2D(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Train2D, self).__init__()\n",
    "        self.net = my_model\n",
    "        self.loss_function = loss_func\n",
    "        self.training_metrics = []\n",
    "        self.validation_metrics = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # returns output of the model --> B Classes H W\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, mask = batch[\"image\"], batch[\"mask\"]  # image --> torch.float(), mask --> torch.Long\n",
    "        img = img.float()  # B Channels H W\n",
    "        mask = mask.long()  # B Channels H W\n",
    "        # image passed through the model\n",
    "        out = self(img)  # B Classes H W\n",
    "        # calculate loss\n",
    "        loss = self.loss_function(out, mask)\n",
    "        # calculate softmax of the prediction\n",
    "        soft_out = soft(out)  # softmax of the prediction\n",
    "        mask = mask.squeeze(dim=1)  # B H W\n",
    "        \"\"\" Calculation of metrics using Torchmetrics\"\"\"\n",
    "        # # calculate iou\n",
    "        # iou_all = IOU_metric(soft_out, mask)\n",
    "        # # train_iou = iou_all.mean()\n",
    "        # iou_all = iou_all[iou_all != -1.]\n",
    "        # if len(iou_all) == 0:\n",
    "        #     train_iou = torch.tensor(0.0).cuda()\n",
    "        # else:\n",
    "        #     train_iou = iou_all.mean()\n",
    "        # # calculate dice score\n",
    "        # dice_all = f1_metric(soft_out, mask)\n",
    "        # # train_dice = dice_all.mean()\n",
    "        # dice_all_np = dice_all.cpu().numpy()\n",
    "        # dice_all_np = dice_all_np[~np.isnan(dice_all_np)]\n",
    "        # dice_all = (torch.from_numpy(dice_all_np).cuda())\n",
    "        # if len(dice_all) == 0:\n",
    "        #     train_dice = torch.tensor(0.0).cuda()\n",
    "        # else:\n",
    "        #     train_dice = dice_all.mean()\n",
    "        \"\"\" Calculation of metrics using Torchmetrics functional\"\"\"\n",
    "        # iou\n",
    "        iou_all = iou(soft_out, mask, absent_score=-1., num_classes=4, reduction='none', ignore_index=None)\n",
    "        iou_all = iou_all[iou_all != -1.]\n",
    "        if len(iou_all) == 0:\n",
    "            train_iou = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            train_iou = iou_all.mean()\n",
    "        # dice score\n",
    "        dice_all = dice_score(soft_out, mask, bg=True, no_fg_score=-1., reduction='none')\n",
    "        dice_all = dice_all[dice_all != -1.]\n",
    "        if len(dice_all) == 0:\n",
    "            train_dice = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            train_dice = dice_all.mean()\n",
    "        # logger --> log the train_loss\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=False)\n",
    "        self.training_metrics.append({\n",
    "            'loss': loss,\n",
    "            'train_iou': train_iou,\n",
    "            'train_dice': train_dice\n",
    "        })\n",
    "        return {\"loss\": loss, \"train_iou\": train_iou, \"train_dice\": train_dice}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, mask = batch[\"image\"], batch[\"mask\"]  # image --> torch.float(), mask --> torch.Long\n",
    "        img = img.float()  # B Channels H W\n",
    "        mask = mask.long()  # B Channels H W\n",
    "        ###############################################\n",
    "        save_plots_image(img, batch_idx)  # save the images\n",
    "        save_plots_mask(mask, batch_idx)  # save the masks\n",
    "        ###############################################\n",
    "        # pad the image\n",
    "        padded_image, ind = Pad_images(img)\n",
    "        padded_image = padded_image.cuda()\n",
    "        # padded image passed through the model\n",
    "        out = self(padded_image).cuda()  # B Classes H W\n",
    "        # unpad the image\n",
    "        unpadded_prediction = UnPad_imges(out, ind, img.shape)\n",
    "        unpadded_prediction = unpadded_prediction.cuda()\n",
    "        ###############################################\n",
    "        save_plots_pred(unpadded_prediction, batch_idx)  # save the predictions\n",
    "        ###############################################\n",
    "        # calculate loss\n",
    "        loss = self.loss_function(unpadded_prediction, mask)\n",
    "        # calculate softmax of the prediction\n",
    "        soft_out = soft(unpadded_prediction)\n",
    "        mask = mask.squeeze(dim=1)  # B H W\n",
    "        \"\"\" Calculation of metrics using Torchmetrics\"\"\"\n",
    "        # # calculate iou\n",
    "        # iou_all = IOU_metric(soft_out, mask)\n",
    "        # # val_iou = iou_all.mean()\n",
    "        # iou_all = iou_all[iou_all != -1.]\n",
    "        # if len(iou_all) == 0:\n",
    "        #     val_iou = torch.tensor(0.0).cuda()\n",
    "        # else:\n",
    "        #     val_iou = iou_all.mean()\n",
    "        # # calculate dice score\n",
    "        # dice_all = f1_metric(soft_out, mask)\n",
    "        # # val_dice = dice_all.mean()\n",
    "        # dice_all_np = dice_all.cpu().numpy()\n",
    "        # dice_all_np = dice_all_np[~np.isnan(dice_all_np)]\n",
    "        # dice_all = (torch.from_numpy(dice_all_np).cuda())\n",
    "        # if len(dice_all) == 0:\n",
    "        #     val_dice = torch.tensor(0.0).cuda()\n",
    "        # else:\n",
    "        #     val_dice = dice_all.mean()\n",
    "        \"\"\" Calculation of metrics using Torchmetrics functional\"\"\"\n",
    "        # iou\n",
    "        iou_all = iou(soft_out, mask, absent_score=-1., num_classes=4, reduction='none', ignore_index=None)\n",
    "        iou_all = iou_all[iou_all != -1.]\n",
    "        if len(iou_all) == 0:\n",
    "            val_iou = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            val_iou = iou_all.mean()\n",
    "        # dice score\n",
    "        dice_all = dice_score(soft_out, mask, bg=True, no_fg_score=-1., reduction='none')\n",
    "        dice_all = dice_all[dice_all != -1.]\n",
    "        if len(dice_all) == 0:\n",
    "            val_dice = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            val_dice = dice_all.mean()\n",
    "        # logger --> log the val_loss\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=False, prog_bar=False)\n",
    "        self.validation_metrics.append({\n",
    "            'loss': loss,\n",
    "            'val_iou': val_iou,\n",
    "            'val_dice': val_dice\n",
    "        })\n",
    "        return {'loss': loss, 'val_iou': val_iou, 'val_dice': val_dice}\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Convert list of dicts to dict of lists\n",
    "        metrics = {key: [d[key] for d in self.training_metrics] for key in self.training_metrics[0]}\n",
    "        \n",
    "        # Convert lists to tensors and calculate mean\n",
    "        avg_train_loss = torch.mean(torch.stack(metrics['loss']))\n",
    "        avg_train_iou = torch.mean(torch.stack(metrics['train_iou']))\n",
    "        avg_train_dice = torch.mean(torch.stack(metrics['train_dice']))\n",
    "        \n",
    "        # Log the averaged metrics\n",
    "        self.log('avg_train_loss', avg_train_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_train_iou', avg_train_iou, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_train_dice', avg_train_dice, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        # Clear the list for the next epoch\n",
    "        self.training_metrics.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Convert list of dicts to dict of lists\n",
    "        metrics = {key: [d[key] for d in self.validation_metrics] for key in self.validation_metrics[0]}\n",
    "        \n",
    "        # Convert lists to tensors and calculate mean\n",
    "        avg_val_loss = torch.mean(torch.stack(metrics['loss']))\n",
    "        avg_val_iou = torch.mean(torch.stack(metrics['val_iou']))\n",
    "        avg_val_dice = torch.mean(torch.stack(metrics['val_dice']))\n",
    "        \n",
    "        # Log the averaged metrics\n",
    "        self.log('avg_val_loss', avg_val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_val_iou', avg_val_iou, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_val_dice', avg_val_dice, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        # Clear the list for the next epoch\n",
    "        self.validation_metrics.clear()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"-----Optimizers and LR Schedulers-----\"\"\"\n",
    "        if optim_choice == 'adam':\n",
    "            optim = torch.optim.Adam(self.net.parameters(), lr=learning_rate, eps=1e-8, weight_decay=1e-5, amsgrad=True)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong optimizer!\")\n",
    "        if scheduler_choice == 'plateau':\n",
    "            scheduler = ReduceLROnPlateau(optim, mode='min', factor=LR_decay_rate, patience=20)\n",
    "        elif scheduler_choice == 'step':\n",
    "            scheduler = StepLR(optim, step_size=10, gamma=LR_decay_rate, last_epoch=-1)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong scheduler!\")\n",
    "        return {\n",
    "            \"optimizer\": optim,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            'monitor': 'avg_train_loss'\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    \"\"\"--------------------------------------5 fold Cross Validation--------------------------------------\"\"\"\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(concatenated_dataset)))):\n",
    "        print(len(train_idx), len(val_idx))\n",
    "        print(\"--------------------------\", \"Fold\", fold + 1, \"--------------------------\")\n",
    "        print(\"Train Batch Size:\", batch_size_train,\n",
    "              \"Val Batch Size:\", batch_size_val,\n",
    "              \"Learning Rate:\", learning_rate,\n",
    "              \"Max epochs:\", max_epochs)\n",
    "\n",
    "        \"\"\"-------------------Train the model for \"max_epochs\" for each fold-------------------\"\"\"\n",
    "        # training dataset\n",
    "        training_data = DataLoader(train_loader_ACDC(transform=train_transform, train_index=train_idx),\n",
    "                                   batch_size=batch_size_train,\n",
    "                                   shuffle=True, num_workers=2, persistent_workers=True)\n",
    "        # validation dataset\n",
    "        validation_data = DataLoader(val_loader_ACDC(transform=val_transform, val_index=val_idx),\n",
    "                                     batch_size=batch_size_val, shuffle=False, num_workers=2, persistent_workers=True)\n",
    "        # init the model\n",
    "        model = Train2D()\n",
    "        # name of the model\n",
    "        name = str(model_choice) + \"_\" + str(drop_rate) + \"_\" + str(datetime.date.today()) + \"_Fold_\" + str(fold + 1)\n",
    "        #  Checkpoint callback and Early Stopping\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=checkpoint_path,\n",
    "                                                           save_top_k=1,\n",
    "                                                           save_last=True,\n",
    "                                                           verbose=True,\n",
    "                                                           monitor='avg_val_iou',\n",
    "                                                           mode='max',\n",
    "                                                           filename=name + \"_\" + '{epoch}-{avg_val_iou:.4f}',\n",
    "                                                           )\n",
    "        early_stop_callback = pl.callbacks.EarlyStopping(monitor='avg_val_loss',\n",
    "                                                         min_delta=0.00,\n",
    "                                                         patience=patience,\n",
    "                                                         verbose=False,\n",
    "                                                         mode='min')\n",
    "        # Tensorboard logger --> tensorboard --logdir=tb_logs\n",
    "        tensorboard_logger = TensorBoardLogger(tb_path, name=name)\n",
    "        # CSV logger\n",
    "        csv_logger = CSVLogger(csv_path, name=name)\n",
    "        # Trainer for training\n",
    "        trainer = Trainer(max_epochs=max_epochs, callbacks=[early_stop_callback, checkpoint_callback],\n",
    "                          devices=1, logger=[tensorboard_logger, csv_logger], fast_dev_run=False, log_every_n_steps=2)\n",
    "        # Training the model\n",
    "        trainer.fit(model, train_dataloaders=training_data, val_dataloaders=validation_data)\n",
    "\n",
    "        # Save the best model\n",
    "        best_model_path = checkpoint_callback.best_model_path\n",
    "        model = Train2D.load_from_checkpoint(best_model_path)\n",
    "        model.eval().cuda()\n",
    "        fname = str(model_choice) + \"_Best_\" + str(drop_rate) + \"_Fold_\" + str(fold + 1)\n",
    "        if not os.path.exists(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/best_models/'):\n",
    "            os.makedirs(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/best_models/')\n",
    "        torch.save(model, str(Path('../unet/best_models/', fname + '.pt')))\n",
    "\n",
    "        # Folders to save the validation images for each fold\n",
    "        if not os.path.exists(os.path.join(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/', name, f\"{fold + 1}_Fold\")):\n",
    "            os.makedirs(os.path.join(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/', name, f\"{fold + 1}_Fold\"))\n",
    "        val_images_path = os.path.join(r'D:\\Kodingan\\Kodingan TA\\\\TA/unet/', name, f\"{fold + 1}_Fold\")\n",
    "\n",
    "        #  Move the validated images to the respective folders\n",
    "        for filename in glob.glob(os.path.join(val_path, '*.*')):\n",
    "            shutil.move(filename, val_images_path)\n",
    "\n",
    "        # Save plots --> Loss, IoU and Dice\n",
    "        plot_out_path = str(Path(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/Plots/\", name))\n",
    "        if not os.path.exists(plot_out_path):\n",
    "            os.makedirs(plot_out_path)\n",
    "\n",
    "        event_acc = ea(str(Path(r\"D:\\Kodingan\\Kodingan TA\\\\TA/unet/tb_logs/\", name, \"version_0\")))\n",
    "        event_acc.Reload()\n",
    "\n",
    "        _, _, training_loss = zip(*event_acc.Scalars('avg_train_loss'))\n",
    "        _, _, validation_loss = zip(*event_acc.Scalars('avg_val_loss'))\n",
    "        _, _, training_iou = zip(*event_acc.Scalars('avg_train_iou'))\n",
    "        _, _, validation_iou = zip(*event_acc.Scalars('avg_val_iou'))\n",
    "        _, _, training_dice = zip(*event_acc.Scalars('avg_train_dice'))\n",
    "        _, _, validation_dice = zip(*event_acc.Scalars('avg_val_dice'))\n",
    "\n",
    "        t_loss, v_loss, t_iou, v_iou, t_dice, v_dice = np.array(training_loss), np.array(validation_loss), \\\n",
    "                                                       np.array(training_iou), np.array(validation_iou), \\\n",
    "                                                       np.array(training_dice), np.array(validation_dice)\n",
    "        min_length = min(len(t_loss), len(v_loss), len(t_iou), len(v_iou), len(t_dice), len(v_dice))\n",
    "        total_epochs = np.arange(1, min_length + 1)\n",
    "\n",
    "        # Save the Loss, IoU and Dice plots\n",
    "        plt.figure(1)\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.plot(total_epochs, t_loss[0:min_length], 'X-', label='Training Loss', linewidth=2.0)\n",
    "        plt.plot(total_epochs, v_loss[0:min_length], 'o-', label='Validation Loss', linewidth=2.0)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle='--')\n",
    "        plt.savefig(str(Path(plot_out_path, 'Loss_Plot.png')), bbox_inches='tight', format='png', dpi=300)\n",
    "        plt.close()  # Always plt.close() to save memory\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.plot(total_epochs, t_iou[0:min_length], 'X-', label='Training IOU', linewidth=2.0)\n",
    "        plt.plot(total_epochs, v_iou[0:min_length], 'o-', label='Validation IOU', linewidth=2.0)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('IOU')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle='--')\n",
    "        plt.savefig(str(Path(plot_out_path, 'Iou_Plot.png')), bbox_inches='tight', format='png', dpi=300)\n",
    "        plt.close()  # Always plt.close() to save memory\n",
    "\n",
    "        plt.figure(3)\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.plot(total_epochs, t_dice[0:min_length], 'X-', label='Training Dice', linewidth=2.0)\n",
    "        plt.plot(total_epochs, v_dice[0:min_length], 'o-', label='Validation Dice', linewidth=2.0)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Dice Score')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle='--')\n",
    "        plt.savefig(str(Path(plot_out_path, 'Dice_Plot.png')), bbox_inches='tight', format='png', dpi=300)\n",
    "        plt.close()  # Always plt.close() to save memory\n",
    "\n",
    "        # reset model parameters after each fold\n",
    "        model.apply(reset_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type     | Params\n",
      "-------------------------------------------\n",
      "0 | net           | Unet_2d  | 17.7 M\n",
      "1 | loss_function | DiceLoss | 0     \n",
      "-------------------------------------------\n",
      "17.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 M    Total params\n",
      "70.628    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 611\n",
      "-------------------------- Fold 1 --------------------------\n",
      "Train Batch Size: 5 Val Batch Size: 1 Learning Rate: 0.0005 Max epochs: 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f59362c840d4473be82ee3b223092dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfff42aee4f46118c02554711517848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447b316fd2794c2aa07073cdc5878bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: RuntimeWarning: You have set 4 number of classes which is different from predicted (2) and target (1) number of classes\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0, global step 122: 'avg_val_iou' reached 0.25059 (best 0.25059), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=0-avg_val_iou=0.2506.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa89ebf2ff98498e802830e32af09951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: RuntimeWarning: You have set 4 number of classes which is different from predicted (2) and target (2) number of classes\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 1, global step 244: 'avg_val_iou' reached 0.38360 (best 0.38360), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=1-avg_val_iou=0.3836.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4893bc8e54024dc7820333eb0acae066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: RuntimeWarning: You have set 4 number of classes which is different from predicted (2) and target (3) number of classes\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 2, global step 366: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0948246a1e734e87a0511e8ae64f78d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 488: 'avg_val_iou' reached 0.50228 (best 0.50228), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=3-avg_val_iou=0.5023.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f71c52602ec48ed97fe916ef54bdb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 610: 'avg_val_iou' reached 0.56090 (best 0.56090), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=4-avg_val_iou=0.5609.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17459c6eda424716870c4c70df12e832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 732: 'avg_val_iou' reached 0.58172 (best 0.58172), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=5-avg_val_iou=0.5817.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4956adc21ba47df920916b0ca810866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 854: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd2409fbaf840e386715b09a376af85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 976: 'avg_val_iou' reached 0.64032 (best 0.64032), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=7-avg_val_iou=0.6403.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b2a66874c0483eac46d9596730c9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1098: 'avg_val_iou' reached 0.69497 (best 0.69497), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=8-avg_val_iou=0.6950.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c897c8723034c7ead7f4a80a7cd670f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1220: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cba0a57b7d408ba26dc12436f41af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1342: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38527bdff1694bfd9a8a196fd0dd7594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1464: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c71a3d04b9f43a3a7fc0ea065599762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1586: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eca70468f8b4206b8213baa83f0d4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1708: 'avg_val_iou' reached 0.70608 (best 0.70608), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=13-avg_val_iou=0.7061.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c76af4d8014307a8cbcaee8836b973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 1830: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665caa51a5e1492dbdbdccb1e1be6583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 1952: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58acdf8ef6d144cba5d3d03ef7f1c234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 2074: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b121ba3f1a514528933998292b9b541e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 2196: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7daae050d744598b4b26aaab36d86dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 2318: 'avg_val_iou' reached 0.70803 (best 0.70803), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=18-avg_val_iou=0.7080.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d2b40acf0a4dfea085980e779aa436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 2440: 'avg_val_iou' reached 0.74842 (best 0.74842), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=19-avg_val_iou=0.7484.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b12f0888868426aba7665dd16ad3872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 2562: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a045873b5de435d9138b24e38a866d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 2684: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84654b1ff9ca4fbfa1f9ce3526f2d994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 2806: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c104d0e9c1b14f7ab5024f6a26d74c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 2928: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e652d24ca0431ea13806ae7c4584c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 3050: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14add167ee1f498682687d39980dca9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 3172: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24461782dc714d61ad9597ea98375e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 3294: 'avg_val_iou' reached 0.75200 (best 0.75200), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=26-avg_val_iou=0.7520.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc7b7ec3ca8455487a3ad6230300d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 3416: 'avg_val_iou' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ebf48f12134def95ed8f8616a03dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 3538: 'avg_val_iou' reached 0.75816 (best 0.75816), saving model to 'D:\\\\Kodingan\\\\Kodingan TA\\\\TA/unet/checkpoints\\\\UNet2D_0.3_2024-03-18_Fold_1_epoch=28-avg_val_iou=0.7582.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7d90cbc66d4d4e9700f3e32db220fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 3660: 'avg_val_iou' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "ename": "DirectoryDeletedError",
     "evalue": "Directory ..\\unet\\tb_logs\\UNet2D_0.3_2024-03-18_Fold_1\\version_0 has been permanently deleted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:88\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_LoadInternal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:110\u001b[0m, in \u001b[0;36mDirectoryWatcher._LoadInternal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loader:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_InitializeLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# If it still doesn't exist, there is no data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:173\u001b[0m, in \u001b[0;36mDirectoryWatcher._InitializeLoader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_InitializeLoader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GetNextPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path:\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:210\u001b[0m, in \u001b[0;36mDirectoryWatcher._GetNextPath\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the next path to load from.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03mThis function also does the checking for out-of-order writes as it iterates\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m  The next path to load events from, or None if there are no more paths.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mio_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mListDirectoryAbsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_filter(path)\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\io_wrapper.py:78\u001b[0m, in \u001b[0;36mListDirectoryAbsolute\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields all files in the given directory.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mThe paths are absolute.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 78\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:896\u001b[0m, in \u001b[0;36mlistdir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 896\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_filesystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:200\u001b[0m, in \u001b[0;36mLocalFileSystem.listdir\u001b[1;34m(self, dirname)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misdir(dirname):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    202\u001b[0m entries \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(compat\u001b[38;5;241m.\u001b[39mas_str_any(dirname))\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 71\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(plot_out_path)\n\u001b[0;32m     70\u001b[0m event_acc \u001b[38;5;241m=\u001b[39m ea(\u001b[38;5;28mstr\u001b[39m(Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../unet/tb_logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion_0\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m---> 71\u001b[0m \u001b[43mevent_acc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m _, _, training_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mevent_acc\u001b[38;5;241m.\u001b[39mScalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_train_loss\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     74\u001b[0m _, _, validation_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mevent_acc\u001b[38;5;241m.\u001b[39mScalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_val_loss\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\event_accumulator.py:343\u001b[0m, in \u001b[0;36mEventAccumulator.Reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads all events added since the last call to `Reload`.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03mIf `Reload` was never called, loads all events in the file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m  The `EventAccumulator`.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator_mutex:\n\u001b[1;32m--> 343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ProcessEvent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Nabil\\anaconda3\\envs\\rgpu\\Lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:92\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory):\n\u001b[1;32m---> 92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DirectoryDeletedError(\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has been permanently deleted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory\n\u001b[0;32m     95\u001b[0m         )\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m: Directory ..\\unet\\tb_logs\\UNet2D_0.3_2024-03-18_Fold_1\\version_0 has been permanently deleted"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
