{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import monai.transforms as mt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_shape = [352, 352]\n",
    "crop_shape = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDC_2D(Dataset):\n",
    "    def __init__(self, source, ind, Transform=None):\n",
    "        # basic transforms\n",
    "        self.loader = mt.LoadImaged(keys=[\"image\", \"mask\"])\n",
    "        self.add_channel = mt.AddChanneld(keys=[\"image\", \"mask\"])\n",
    "        self.spatial_pad = mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\")\n",
    "        self.spacing = mt.Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.25, 1.25, -1.0), mode=(\"nearest\", \"nearest\"))\n",
    "        # index\n",
    "        self.ind = ind\n",
    "        # transform\n",
    "        if Transform is not None:\n",
    "            self.transform = Transform\n",
    "        else:\n",
    "            self.transform = mt.Compose([\n",
    "                mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\"),\n",
    "                mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False)\n",
    "            ])\n",
    "\n",
    "        # take the images\n",
    "        source = Path(source)\n",
    "        dirs = os.listdir(str(source))  # stores patient name\n",
    "        all_data_ed = []\n",
    "        all_data_ed_mask = []\n",
    "        all_data_es = []\n",
    "        all_data_es_mask = []\n",
    "        for filenames in dirs:\n",
    "            patient_path = Path(str(source), filenames)  # individual patient path\n",
    "            patient_info = str(patient_path) + \"/Info.cfg\"  # patient information\n",
    "            file = open(patient_info, 'r').readlines()\n",
    "            ED_frame = int(file[0].split(\":\")[1])\n",
    "            ES_frame = int(file[1].split(\":\")[1])\n",
    "            ED = Path(str(patient_path), filenames + \"_frame{:02d}.nii.gz\".format(ED_frame))\n",
    "            ES = Path(str(patient_path), filenames + \"_frame{:02d}.nii.gz\".format(ES_frame))\n",
    "            ED_gt = Path(str(patient_path), filenames + \"_frame{:02d}_gt.nii.gz\".format(ED_frame))\n",
    "            ES_gt = Path(str(patient_path), filenames + \"_frame{:02d}_gt.nii.gz\".format(ES_frame))\n",
    "            all_data_ed.append(ED)\n",
    "            all_data_ed_mask.append(ED_gt)\n",
    "            all_data_es.append(ES)\n",
    "            all_data_es_mask.append(ES_gt)\n",
    "\n",
    "        if self.ind is not None:\n",
    "            all_data_ed = [all_data_ed[i] for i in self.ind]\n",
    "            all_data_ed_mask = [all_data_ed_mask[i] for i in self.ind]\n",
    "            all_data_es = [all_data_es[i] for i in self.ind]\n",
    "            all_data_es_mask = [all_data_es_mask[i] for i in self.ind]\n",
    "\n",
    "        self.data = [all_data_ed, all_data_ed_mask, all_data_es, all_data_es_mask]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ED_img, ED_mask, ES_img, ES_mask = self.data[0][idx], self.data[1][idx], self.data[2][idx], self.data[3][idx]\n",
    "        # data dict\n",
    "        ED_data_dict = {\"image\": ED_img,\n",
    "                        \"mask\": ED_mask}\n",
    "        ES_data_dict = {\"image\": ES_img,\n",
    "                        \"mask\": ES_mask}\n",
    "        # instead of returning both ED and ES, I have to return just a random choice between ED and ES(image and mask)\n",
    "        datalist = [ED_data_dict, ES_data_dict]\n",
    "        data_return = np.random.choice(datalist)\n",
    "        data_return = self.loader(data_return)\n",
    "        data_return = self.add_channel(data_return)\n",
    "        data_return = self.spacing(data_return)\n",
    "        data_return[\"image\"] = normalize(data_return[\"image\"])\n",
    "        num_slice = data_return[\"image\"].shape[3]\n",
    "        random_slice = random.randint(0, num_slice - 1)\n",
    "        data_return[\"image\"] = data_return[\"image\"][:, :, :, random_slice]\n",
    "        data_return[\"image\"] = normalize(data_return[\"image\"])\n",
    "        data_return[\"mask\"] = data_return[\"mask\"][:, :, :, random_slice]\n",
    "        data_return = self.transform(data_return)\n",
    "        return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loader_ACDC(train_index, data_path=r\"D:\\Kodingan\\Kodingan TA\\database\\\\training\", transform=None):\n",
    "    train_loader = ACDC_2D(source=data_path, Transform=transform, ind=train_index)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def val_loader_ACDC(val_index, data_path=r\"D:\\Kodingan\\Kodingan TA\\database\\\\training\", transform=None):\n",
    "    val_loader = ACDC_2D(source=data_path, Transform=transform, ind=val_index)\n",
    "    return val_loader\n",
    "\n",
    "\n",
    "def test_loader_ACDC(test_index, data_path=r\"D:\\Kodingan\\Kodingan TA\\database\\\\training\", transform=None):\n",
    "    test_loader = ACDC_2D(source=data_path, Transform=transform, ind=test_index)\n",
    "    return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_compose = mt.Compose(\n",
    "    [mt.SpatialPadD(keys=[\"image\", \"mask\"], spatial_size=tar_shape, mode=\"edge\"),\n",
    "     mt.RandSpatialCropD(keys=[\"image\", \"mask\"], roi_size=crop_shape, random_center=True, random_size=False),\n",
    "     \n",
    "     mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "     ]\n",
    ")\n",
    "\n",
    "val_compose = mt.Compose(\n",
    "    [\n",
    "        mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_compose = mt.Compose(\n",
    "    [\n",
    "        mt.DivisiblePadD(keys=[\"image\", \"mask\"], k=(16, 16), mode=\"edge\"),\n",
    "        mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "splits = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "concatenated_dataset = train_loader_ACDC(transform=None, train_index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = KFold(n_splits=2, shuffle=True, random_state=4)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(test_split.split(np.arange(len(concatenated_dataset)))):\n",
    "\n",
    "    print(\"--------------------------\", \"Fold\", fold + 1, \"--------------------------\")\n",
    "\n",
    "    # training dataset\n",
    "    training_data = DataLoader(train_loader_ACDC(transform=train_compose, train_index=train_idx), batch_size=5,\n",
    "                               shuffle=True)\n",
    "    print(\"train from here\")\n",
    "    for dic in training_data:\n",
    "        images = dic[\"image\"]\n",
    "        masks = dic[\"mask\"]\n",
    "        print(images.shape, masks.shape)\n",
    "        image, label = dic[\"image\"], dic[\"mask\"]\n",
    "        plt.figure(\"visualise\", (8, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"image\")\n",
    "        plt.imshow(image[0, 0, :, :], cmap=\"gray\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"mask\")\n",
    "        plt.imshow(label[0, 0, :, :], cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(concatenated_dataset)))):\n",
    "\n",
    "    print(\"--------------------------\", \"Fold\", fold + 1, \"--------------------------\")\n",
    "\n",
    "    # training dataset\n",
    "    training_data = DataLoader(train_loader_ACDC(transform=train_compose, train_index=train_idx), batch_size=5,\n",
    "                               shuffle=True)\n",
    "    print(\"train from here\")\n",
    "    for dic in training_data:\n",
    "        images = dic[\"image\"]\n",
    "        masks = dic[\"mask\"]\n",
    "        # print(images.shape, masks.shape)\n",
    "        # image, label = dic[\"image\"], dic[\"mask\"]\n",
    "        # plt.figure(\"visualise\", (8, 4))\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.title(\"image\")\n",
    "        # plt.imshow(image[0, 0, :, :], cmap=\"gray\")\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.title(\"mask\")\n",
    "        # plt.imshow(label[0, 0, :, :], cmap=\"gray\")\n",
    "        # plt.show()\n",
    "\n",
    "    # validation dataset\n",
    "    validation_data = DataLoader(val_loader_ACDC(transform=val_compose, val_index=val_idx), batch_size=1,\n",
    "                                 shuffle=False)\n",
    "    print(\"val from here\")\n",
    "    for dic in validation_data:\n",
    "        images = dic[\"image\"]\n",
    "        masks = dic[\"mask\"]\n",
    "        # print(images.shape, masks.shape)\n",
    "        # image, label = dic[\"image\"], dic[\"mask\"]\n",
    "        # plt.figure(\"visualise\", (8, 4))\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.title(\"image\")\n",
    "        # plt.imshow(image[0, 0, :, :], cmap=\"gray\")\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.title(\"mask\")\n",
    "        # plt.imshow(label[0, 0, :, :], cmap=\"gray\")\n",
    "        # plt.show()\n",
    "\n",
    "    # test dataset\n",
    "    test_data = DataLoader(test_loader_ACDC(transform=test_compose, test_index=None), batch_size=1, shuffle=False)\n",
    "    print(\"test from here\")\n",
    "    for dic in test_data:\n",
    "        images = dic[\"image\"]\n",
    "        masks = dic[\"mask\"]\n",
    "        print(images.shape, masks.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
